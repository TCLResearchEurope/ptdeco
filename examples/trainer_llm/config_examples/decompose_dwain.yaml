# From run_phi2_ft.py
task: decompose_dwain
proportion_threshold: 0.75
ppl_diff_threshold: 0.005
nsr_final_threshold: 1.0
num_data_steps: 1024
num_metric_steps: 10
num_ft_steps: 20
min_proportion: 0.25
ft_lr: 0.0001
run_finetuning: false
trade_off_factor: 1.0
start_layer_num: 0
end_layer_num: 23
min_rank: 4
max_length: 512
batch_size: 1
blacklisted_module_names:
  - model.lm_head
    # model.model.decoder.layers.0.self_attn.k_proj
    # model.model.decoder.layers.0.self_attn.v_proj
    # model.model.decoder.layers.0.self_attn.q_proj
    # model.model.decoder.layers.0.self_attn.out_proj
    # model.model.decoder.layers.0.fc1
    # model.model.decoder.layers.0.fc2
  - model.model.decoder.layers.1.self_attn.k_proj
  - model.model.decoder.layers.1.self_attn.v_proj
  - model.model.decoder.layers.1.self_attn.q_proj
  - model.model.decoder.layers.1.self_attn.out_proj
  - model.model.decoder.layers.1.fc1
  - model.model.decoder.layers.1.fc2
  - model.model.decoder.layers.2.self_attn.k_proj
  - model.model.decoder.layers.2.self_attn.v_proj
  - model.model.decoder.layers.2.self_attn.q_proj
  - model.model.decoder.layers.2.self_attn.out_proj
  - model.model.decoder.layers.2.fc1
  - model.model.decoder.layers.2.fc2
  - model.model.decoder.layers.3.self_attn.k_proj
  - model.model.decoder.layers.3.self_attn.v_proj
  - model.model.decoder.layers.3.self_attn.q_proj
  - model.model.decoder.layers.3.self_attn.out_proj
  - model.model.decoder.layers.3.fc1
  - model.model.decoder.layers.3.fc2
  - model.model.decoder.layers.4.self_attn.k_proj
  - model.model.decoder.layers.4.self_attn.v_proj
  - model.model.decoder.layers.4.self_attn.q_proj
  - model.model.decoder.layers.4.self_attn.out_proj
  - model.model.decoder.layers.4.fc1
  - model.model.decoder.layers.4.fc2
  - model.model.decoder.layers.5.self_attn.k_proj
  - model.model.decoder.layers.5.self_attn.v_proj
  - model.model.decoder.layers.5.self_attn.q_proj
  - model.model.decoder.layers.5.self_attn.out_proj
  - model.model.decoder.layers.5.fc1
  - model.model.decoder.layers.5.fc2
  - model.model.decoder.layers.6.self_attn.k_proj
  - model.model.decoder.layers.6.self_attn.v_proj
  - model.model.decoder.layers.6.self_attn.q_proj
  - model.model.decoder.layers.6.self_attn.out_proj
  - model.model.decoder.layers.6.fc1
  - model.model.decoder.layers.6.fc2
  - model.model.decoder.layers.7.self_attn.k_proj
  - model.model.decoder.layers.7.self_attn.v_proj
  - model.model.decoder.layers.7.self_attn.q_proj
  - model.model.decoder.layers.7.self_attn.out_proj
  - model.model.decoder.layers.7.fc1
  - model.model.decoder.layers.7.fc2
  - model.model.decoder.layers.8.self_attn.k_proj
  - model.model.decoder.layers.8.self_attn.v_proj
  - model.model.decoder.layers.8.self_attn.q_proj
  - model.model.decoder.layers.8.self_attn.out_proj
  - model.model.decoder.layers.8.fc1
  - model.model.decoder.layers.8.fc2
  - model.model.decoder.layers.9.self_attn.k_proj
  - model.model.decoder.layers.9.self_attn.v_proj
  - model.model.decoder.layers.9.self_attn.q_proj
  - model.model.decoder.layers.9.self_attn.out_proj
  - model.model.decoder.layers.9.fc1
  - model.model.decoder.layers.9.fc2
  - model.model.decoder.layers.10.self_attn.k_proj
  - model.model.decoder.layers.10.self_attn.v_proj
  - model.model.decoder.layers.10.self_attn.q_proj
  - model.model.decoder.layers.10.self_attn.out_proj
  - model.model.decoder.layers.10.fc1
  - model.model.decoder.layers.10.fc2
  - model.model.decoder.layers.11.self_attn.k_proj
  - model.model.decoder.layers.11.self_attn.v_proj
  - model.model.decoder.layers.11.self_attn.q_proj
  - model.model.decoder.layers.11.self_attn.out_proj
  - model.model.decoder.layers.11.fc1
  - model.model.decoder.layers.11.fc2
